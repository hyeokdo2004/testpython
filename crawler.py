# crawler.py
import requests
import re
import os

BASE_URL = "https://www.koref.or.kr"
BOARD_ID = 27
LIST_PAGE_URL = f"{BASE_URL}/web/board/boardContentsListPage.do?board_id={BOARD_ID}"
AJAX_URL = f"{BASE_URL}/web/board/boardContentsList.do"

OUTPUT_DIR = "docs"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "collected_contents_ids.txt")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ì„¸ì…˜ ë° í—¤ë”
session = requests.Session()
headers = {
    "User-Agent": "Mozilla/5.0",
    "X-Requested-With": "XMLHttpRequest",
    "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
    "Referer": LIST_PAGE_URL
}

# AJAX ìš”ì²­ íŒŒë¼ë¯¸í„° (ì²« í˜ì´ì§€)
data = {
    "board_id": BOARD_ID,
    "miv_pageNo": 1
}

try:
    resp = session.post(AJAX_URL, headers=headers, data=data, timeout=15)
    resp.raise_for_status()
except requests.RequestException as e:
    print(f"âš ï¸ AJAX ìš”ì²­ ì‹¤íŒ¨: {e}")
    exit(1)

try:
    json_data = resp.json()
except Exception as e:
    print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    exit(1)

board_list = json_data.get("boardList", [])
contents_ids = []

for item in board_list:
    onclick_val = item.get("onclick", "")
    # contentsView('572b4a95fc0e43c39900d9b7a4d39091')
    m = re.search(r"contentsView\(['\"]([0-9a-fA-F]+)['\"]\)", onclick_val)
    if m:
        contents_ids.append(m.group(1))

# íŒŒì¼ ì €ì¥
with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    for cid in contents_ids:
        f.write(cid + "\n")

print(f"ğŸ”— í˜ì´ì§€ ì ‘ì†: {LIST_PAGE_URL}")
print(f"âœ… ì´ {len(contents_ids)}ê°œ contents_id ì¶”ì¶œ")
print(f"âœ… ê²°ê³¼ ì €ì¥ â†’ {OUTPUT_FILE}")
