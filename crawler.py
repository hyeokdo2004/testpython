# crawler.py
import asyncio
from playwright.async_api import async_playwright
import re
import os

# ìˆ˜ì§‘í•  ê²Œì‹œíŒ URL (ì²« í˜ì´ì§€ë§Œ)
BOARD_URLS = [
    "https://www.koref.or.kr/web/board/boardContentsListPage.do?board_id=27"
]

# contents_id ì¶”ì¶œìš© ì •ê·œì‹
RE_CONTENTS = re.compile(r"contentsView\(['\"]([0-9a-fA-F]+)['\"]\)")

# ê²°ê³¼ íŒŒì¼
OUTPUT_FILE = os.path.join("docs", "collected_contents_ids.txt")
os.makedirs("docs", exist_ok=True)

async def crawl_board(page, url):
    print(f"ğŸ”— í˜ì´ì§€ ì ‘ì†: {url}")
    await page.goto(url, timeout=60000)
    await page.wait_for_load_state("networkidle")
    await asyncio.sleep(2)  # AJAX ë Œë”ë§ ëŒ€ê¸°

    # í˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸°
    html = await page.content()

    # contents_id ì¶”ì¶œ
    ids = RE_CONTENTS.findall(html)
    print(f"âœ… ì´ {len(ids)}ê°œ contents_id ì¶”ì¶œ")

    # íŒŒì¼ ì €ì¥
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for cid in ids:
            f.write(cid + "\n")

async def main():
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        context = await browser.new_context()
        page = await context.new_page()

        for url in BOARD_URLS:
            await crawl_board(page, url)

        await context.close()
        await browser.close()
        print(f"âœ… ê²°ê³¼ ì €ì¥ â†’ {OUTPUT_FILE}")

if __name__ == "__main__":
    asyncio.run(main())
