import os
import requests
from bs4 import BeautifulSoup

BASE_DOMAIN = "https://www.koref.or.kr"
BOARD_IDS = [27, 49, 28, 29, 30, 50, 51, 52, 39, 37, 32]
LIST_URL = f"{BASE_DOMAIN}/web/board/boardContentsList.do"

def crawl_board(board_id):
    urls = []
    data = {"board_id": board_id, "miv_pageNo": 1}
    res = requests.post(LIST_URL, data=data, timeout=20)
    res.encoding = "utf-8"

    if "contentsView" not in res.text:
        print(f"âš ï¸ board_id={board_id}: ê²Œì‹œë¬¼ ì—†ìŒ ë˜ëŠ” ë¹„ì •ìƒ ì‘ë‹µ")
        return urls

    soup = BeautifulSoup(res.text, "html.parser")
    for a in soup.select("a[href*='contentsView']"):
        href = a.get("href", "")
        if "contentsView" in href:
            urls.append(BASE_DOMAIN + href.replace("javascript:", ""))

    print(f"âœ… board_id={board_id}: {len(urls)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
    return urls

def main():
    os.makedirs("docs", exist_ok=True)
    out_path = os.path.join("docs", "collected_urls.txt")

    all_urls = []
    for bid in BOARD_IDS:
        urls = crawl_board(bid)
        all_urls.extend(urls)

    with open(out_path, "w", encoding="utf-8") as f:
        for u in all_urls:
            f.write(u + "\n")

    print(f"\nğŸ“ ì´ {len(all_urls)}ê°œ URL ì €ì¥ ì™„ë£Œ â†’ {out_path}")

if __name__ == "__main__":
    main()
