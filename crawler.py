# crawler.py
import asyncio
from playwright.async_api import async_playwright
import re
import os

BOARD_ID = 27  # í…ŒìŠ¤íŠ¸ìš©, í•„ìš”í•˜ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ í™•ì¥ ê°€ëŠ¥
BASE_URL = "https://www.koref.or.kr"
LIST_PAGE = f"{BASE_URL}/web/board/boardContentsListPage.do?board_id={BOARD_ID}"

OUTPUT_FILE = os.path.join("docs", "collected_contents_ids.txt")
os.makedirs("docs", exist_ok=True)

# contents_id ì¶”ì¶œìš© ì •ê·œì‹
RE_CONTENTS = re.compile(r"contentsView\(['\"]?([0-9a-fA-F]+)['\"]?\)")

async def main():
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        page = await browser.new_page()
        print(f"\nğŸ”— í˜ì´ì§€ ì ‘ì†: {LIST_PAGE}")
        await page.goto(LIST_PAGE, timeout=60000)
        await page.wait_for_load_state("networkidle")

        # í˜ì´ì§€ ì „ì²´ HTML ê°€ì ¸ì˜¤ê¸°
        html = await page.content()

        # contents_id ì¶”ì¶œ
        ids = RE_CONTENTS.findall(html)
        print(f"âœ… ì´ {len(ids)}ê°œ contents_id ì¶”ì¶œ")

        # ê²°ê³¼ ì €ì¥
        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            for cid in ids:
                f.write(cid + "\n")

        print(f"âœ… ê²°ê³¼ ì €ì¥ â†’ {OUTPUT_FILE}")

        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())
