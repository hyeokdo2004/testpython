# crawler.py
import requests
import os

# ê²Œì‹œíŒ ID ë¦¬ìŠ¤íŠ¸
BOARD_IDS = [27, 49, 28, 29, 30, 50, 51, 52, 39, 37, 32]

BASE_DOMAIN = "https://www.koref.or.kr"
LIST_URL = BASE_DOMAIN + "/web/board/boardContentsList.do"
DETAIL_URL_TPL = BASE_DOMAIN + "/web/board/boardContentsView.do?board_id={}&contents_id={}"
FILE_URL_TPL = BASE_DOMAIN + "/web/board/fileDownload.do?file_id={}"

OUTPUT_FILE = os.path.join("docs", "collected_urls.txt")
os.makedirs("docs", exist_ok=True)

# ì„¸ì…˜ ìœ ì§€
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0",
    "X-Requested-With": "XMLHttpRequest",
    "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
})

total_count = 0

for board_id in BOARD_IDS:
    print(f"\nğŸ“ ê²Œì‹œíŒ board_id={board_id} ìˆ˜ì§‘ ì‹œì‘")

    page_no = 1
    while True:
        data = {
            "board_id": board_id,
            "miv_pageNo": page_no,
            # í•„ìš”í•˜ë©´ hidden form ê°’ ë“± ì¶”ê°€ ê°€ëŠ¥
        }

        try:
            resp = session.post(LIST_URL, data=data)
            resp.raise_for_status()
            json_data = resp.json()
        except Exception as e:
            print(f" âš ï¸ board_id={board_id}, page={page_no} ìš”ì²­/íŒŒì‹± ì˜¤ë¥˜: {e}")
            break

        board_list = json_data.get("boardList", [])
        if not board_list:
            if page_no == 1:
                print(f" âš ï¸ board_id={board_id}: ê²Œì‹œë¬¼ì´ ì—†ìŒ")
            break

        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            for board in board_list:
                contents_id = board.get("contents_id")
                file_id = board.get("file_id")

                # ê²Œì‹œë¬¼ ìƒì„¸ URL
                detail_url = DETAIL_URL_TPL.format(board_id, contents_id)
                f.write(detail_url + "\n")
                total_count += 1
                print(f" ğŸ“° ê²Œì‹œë¬¼: {detail_url}")

                # ì²¨ë¶€íŒŒì¼ URL
                if file_id:
                    file_url = FILE_URL_TPL.format(file_id)
                    f.write(file_url + "\n")
                    print(f" â””â”€â”€ ì²¨ë¶€íŒŒì¼: {file_url}")

        page_no += 1

print(f"\nğŸ“ ì´ {total_count}ê°œ ê²Œì‹œë¬¼ URL ë° ì²¨ë¶€íŒŒì¼ URL ì €ì¥ ì™„ë£Œ â†’ {OUTPUT_FILE}")
