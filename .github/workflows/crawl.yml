name: Koref Crawler

on:
  # 수동 실행
  workflow_dispatch:

  # 매주 월요일 새벽 00시 자동 실행
  schedule:
    - cron: '0 15 * * 0'  # UTC 기준 15시 = 한국 시간 월요일 00시

jobs:
  run-crawler:
    runs-on: ubuntu-latest

    steps:
      # ✅ 저장소 체크아웃
      - name: Checkout repository
        uses: actions/checkout@v4

      # ✅ Python 설치
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # ✅ Playwright 및 필요한 라이브러리 설치
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright
          playwright install --with-deps chromium

      # ✅ 크롤러 실행
      - name: Run crawler
        run: python crawler.py

      # ✅ 결과를 GitHub Pages용 docs 폴더로 복사
      - name: Copy result to docs folder
        run: |
          mkdir -p docs
          cp result_urls.json docs/result_urls.json

      # ✅ 결과 파일 자동 커밋 및 푸시
      - name: Commit result to GitHub Pages
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add docs/result_urls.json
          git commit -m "Update result URLs [skip ci]" || echo "No changes to commit"
          git push
